{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webs = pd.ExcelFile(\"Webs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(webs.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = webs.parse(\"Categorias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = pd.DataFrame(columns=['Texto', 'Clase'])\n",
    "\n",
    "for i in df.index: \n",
    "    print(\"i\", i)\n",
    "    url = df[\"URL\"][i]\n",
    "    req = requests.get(url)\n",
    "    statusCode = req.status_code\n",
    "    html = BeautifulSoup(req.text, \"html.parser\")\n",
    "    if statusCode == 200:\n",
    "        paragraphs = html.select(\"p\")\n",
    "        cont = 0\n",
    "        for para in paragraphs:\n",
    "            if cont == 20:\n",
    "               cont = 0\n",
    "               time.sleep(1)\n",
    "            cont += 1 \n",
    "            parrafo = \"\"\n",
    "            print(\"parrafo\",parrafo) \n",
    "            print(\"i\",i) \n",
    "            print(\"df['CÓDIGO'][i]\",df[\"CÓDIGO\"][i]) \n",
    "            print('df[\"NOMBRE ARCHIVO\"][i]',df[\"NOMBRE ARCHIVO\"][i])\n",
    "            print(\"cont\",cont) \n",
    "            guardarComo = str(df[\"CÓDIGO\"][i]) + \"/\"  + df[\"NOMBRE ARCHIVO\"][i] + str(cont)\n",
    "            print(\"guardarComo\",guardarComo)  \n",
    "            parrafo = open(guardarComo,\"w\",encoding = \"utf-8\") \n",
    "            parrafo.write(para.text)\n",
    "            textos = textos.append({'Texto': para.text, 'Clase':df[\"CÓDIGO\"][i]}, ignore_index=True)\n",
    "            parrafo.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos.to_csv(\"Historia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = pd.read_csv(\"Historia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos.groupby(by=[\"Clase\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos[\"Longitud\"] = len(textos[\"Texto\"])\n",
    "textos.sample(20)\n",
    "textos.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in textos.index:\n",
    "    textos.loc[i, \"Longitud\"] = len(textos.loc[i, \"Texto\"])\n",
    "textos.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos =  textos.sort_values('Longitud',ascending = True)\n",
    "textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menoresDeCien = textos.apply(lambda x: True if x['Longitud'] < 100 else False , axis=1)\n",
    "# Count number of True in series\n",
    "numOfRows = len(menoresDeCien[menoresDeCien == True].index)\n",
    "print('Number of Rows in dataframe in whichLongitud < 100 : ', numOfRows)\n",
    "textos.groupby(by=[\"Clase\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = textos.drop(textos[textos['Longitud'] < 100].index)\n",
    "textos.groupby(by=[\"Clase\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menoresDeCien = textos.apply(lambda x: True if x['Longitud'] > 1500 else False , axis=1)\n",
    "# Count number of True in series\n",
    "numOfRows = len(menoresDeCien[menoresDeCien == True].index)\n",
    "print('Number of Rows in dataframe in whichLongitud > 1500 : ', numOfRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = textos.drop(textos[textos['Longitud'] > 1500].index)\n",
    "textos.groupby(by=[\"Clase\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
    "import matplotlib.pyplot as plt            # library for visualization\n",
    "import random                              # pseudo-random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the stopwords from NLTK\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                  # library for regular expression operations\n",
    "import string                              # for string operations\n",
    "\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textosSlice = textos.iloc[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textosSlice.head(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textosSlice.head().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textoPrueba = textosSlice[\"Texto\"].values[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textoPrueba) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textoPrueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textoPrueba = textoPrueba + \" 1984\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print('\\033[92m' + textoPrueba)\n",
    "print('\\033[94m')\n",
    "\n",
    "# instantiate tokenizer class\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "\n",
    "# tokenize tweets\n",
    "texto_tokens = tokenizer.tokenize(textoPrueba)\n",
    "\n",
    "print()\n",
    "print('Tokenized string:')\n",
    "print(texto_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the english stop words list from NLTK\n",
    "stopwords_english = stopwords.words('english') \n",
    "\n",
    "print('Stop words\\n')\n",
    "print(stopwords_english)\n",
    "\n",
    "print('\\nPunctuation\\n')\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print('\\033[92m')\n",
    "print(tweet_tokens)\n",
    "print('\\033[94m')\n",
    "\n",
    "texto_clean = []\n",
    "\n",
    "for word in texto_tokens: # Go through every word in your tokens list\n",
    "    if (word not in stopwords_english and  # remove stopwords\n",
    "        word not in string.punctuation):  # remove punctuation\n",
    "        texto_clean.append(word)\n",
    "\n",
    "print('removed stop words and punctuation:')\n",
    "print(texto_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print('\\033[92m')\n",
    "print(texto_clean)\n",
    "print('\\033[94m')\n",
    "\n",
    "# Instantiate stemming class\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "# Create an empty list to store the stems\n",
    "texto_stem = [] \n",
    "\n",
    "for word in texto_clean:\n",
    "    stem_word = stemmer.stem(word)  # stemming word\n",
    "    texto_stem.append(stem_word)  # append to the list\n",
    "\n",
    "print('stemmed words:')\n",
    "print(texto_stem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
